# =========================
# Multimodal Housing Price (Images + Tabular) â€” No Kaggle
# Dataset: Houses-dataset (535 homes, 4 real photos/home + metadata)
# =========================

# 0) Setup
!git clone -q https://github.com/emanhamed/Houses-dataset.git
import os, glob, math, random, warnings
warnings.filterwarnings("ignore")

DATA_DIR = "/content/Houses-dataset/Houses Dataset"
assert os.path.exists(DATA_DIR), "Dataset folder missing."

# 1) Imports
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras import layers, models

# 2) Load metadata
# The dataset provides: [bedrooms, bathrooms, area, zipcode, price]
# File name is "HousesInfo.txt" inside the dataset folder.
meta_path = os.path.join(DATA_DIR, "HousesInfo.txt")
cols = ["bed", "bath", "area", "zipcode", "price"]
df = pd.read_csv(meta_path, delim_whitespace=True, header=None, names=cols)

# The images are named like: "1_bathroom.jpg", "1_bedroom.jpg", "1_kitchen.jpg", "1_house.jpg", etc.
# We'll build a 2x2 montage for each row index i => files matching f"{i+1}_*"
def load_house_montage(idx, base_path=DATA_DIR, tile=128):
    """
    Create a 2x2 montage (bath, bed, front, kitchen) for house index `idx`.
    If any image is missing, return None.
    """
    # Find the 4 images for this house
    house_paths = sorted(glob.glob(os.path.join(base_path, f"{idx+1}_*")))
    if len(house_paths) < 4:
        return None  # skip if incomplete

    # Try to keep a consistent order by filename sort; optionally re-order to a canonical layout
    # We'll sort and then tile in the same order each time.
    imgs = []
    for p in house_paths[:4]:
        img = cv2.imread(p)
        if img is None:
            return None
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (tile, tile))
        imgs.append(img)

    # Build a 2x2 tile
    top = np.hstack((imgs[0], imgs[1]))
    bottom = np.hstack((imgs[2], imgs[3]))
    montage = np.vstack((top, bottom))
    return montage

# 3) Build image dataset (montages)
tile = 128  # each cell in the 2x2 tile (final image 256x256)
images = []
keep_indices = []
for i in range(len(df)):
    m = load_house_montage(i, DATA_DIR, tile=tile)
    if m is not None:
        images.append(m)
        keep_indices.append(i)

images = np.array(images, dtype="uint8")
df = df.iloc[keep_indices].reset_index(drop=True)
assert len(df) == len(images) > 0, "No images were loaded. Check paths."

print(f"Loaded {len(df)} houses and {images.shape[0]} montages of shape {images.shape[1:]}")

# 4) Quick peek
plt.figure(figsize=(12,4))
for i in range(3):
    plt.subplot(1,3,i+1)
    plt.imshow(images[i])
    plt.title(f"${df['price'].iloc[i]:,.0f} | {df['bed'].iloc[i]}bd/{df['bath'].iloc[i]}ba | {df['area'].iloc[i]} sqft")
    plt.axis('off')
plt.tight_layout()
plt.show()

# 5) Train/validation split
X_tab = df[["bed", "bath", "area", "zipcode"]].copy()
y = df["price"].astype(float)

X_img = images.copy()  # (N, 256, 256, 3) since tile=128 => montage size 256x256

X_tab_train, X_tab_test, X_img_train, X_img_test, y_train, y_test = train_test_split(
    X_tab, X_img, y, test_size=0.2, random_state=42
)

# 6) Tabular pipeline (one-hot zipcode + scale numerics)
numeric_features = ["bed", "bath", "area"]
categorical_features = ["zipcode"]

tab_preproc = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numeric_features),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features),
    ]
)

X_tab_train_proc = tab_preproc.fit_transform(X_tab_train)
X_tab_test_proc  = tab_preproc.transform(X_tab_test)

print("Tabular features shape:", X_tab_train_proc.shape)

# 7) Image feature extractor (pretrained CNN)
# Use MobileNetV2 on 224x224 crops; we'll resize montages down and take global pooled features.
IMG_INPUT = 224
def prep_images(x):
    # Resize montages to 224x224 for MobileNetV2
    x = tf.image.resize(x, (IMG_INPUT, IMG_INPUT))
    return preprocess_input(x)

base_cnn = MobileNetV2(weights="imagenet", include_top=False, input_shape=(IMG_INPUT, IMG_INPUT, 3))
base_cnn.trainable = False  # feature extractor

img_input = tf.keras.Input(shape=(X_img_train.shape[1], X_img_train.shape[2], 3))
x = layers.Lambda(prep_images)(img_input)
x = base_cnn(x)
x = layers.GlobalAveragePooling2D()(x)  # image embedding
img_encoder = tf.keras.Model(img_input, x, name="image_encoder")

# Extract embeddings to numpy (for a simple concatenation model)
img_train_embed = img_encoder.predict(X_img_train, verbose=0)
img_test_embed  = img_encoder.predict(X_img_test,  verbose=0)
print("Image embedding shape:", img_train_embed.shape)

# 8) Fusion model: concatenate image + tabular and train MLP regressor
in_img = tf.keras.Input(shape=(img_train_embed.shape[1],))
in_tab = tf.keras.Input(shape=(X_tab_train_proc.shape[1],))

z = layers.Concatenate()([in_img, in_tab])
z = layers.Dense(256, activation="relu")(z)
z = layers.Dropout(0.3)(z)
z = layers.Dense(128, activation="relu")(z)
z = layers.Dropout(0.2)(z)
out = layers.Dense(1, activation="linear")(z)

fusion_model = tf.keras.Model([in_img, in_tab], out)
fusion_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss="mse", metrics=["mae"])

history = fusion_model.fit(
    [img_train_embed, X_tab_train_proc], y_train,
    validation_split=0.2,
    epochs=50,
    batch_size=16,
    verbose=1
)

# 9) Evaluate
y_pred = fusion_model.predict([img_test_embed, X_tab_test_proc]).ravel()
mae  = mean_absolute_error(y_test, y_pred)
rmse = math.sqrt(mean_squared_error(y_test, y_pred))
print(f"\nFinal Evaluation:")
print(f"MAE : ${mae:,.0f}")
print(f"RMSE: ${rmse:,.0f}")

# 10) Plot Actual vs Predicted
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.7)
mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
plt.plot([mn, mx], [mn, mx], 'r--')
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("House Price Prediction (Multimodal: Images + Tabular)")
plt.tight_layout()
plt.show()
